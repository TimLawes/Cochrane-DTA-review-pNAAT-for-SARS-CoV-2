---
title: "R Notebook for Cochrane systematic review on pNAAT for SARS-CoV-2"
output:
  html_notebook:
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    toc: yes
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook including code for all analyses within the Cochrane Review on Pooled versus individual nucleic acid amplification testing (pNAAT) for detection of active SARS-CoV-2 infection. It requires the following datasets 

* pnaat_desc_study.csv
* pnaat_desc.csv


# 1. Preliminaries

## 1.1 Check working directory
Open the R project associated with this notebook to ensure the working directory is set to ~/Cochrane-DTA-review-pNAAT-for-SARS-CoV-2

## 1.2 Load packages required
This project will initialise *renv*  when opened. The R package *renv* creates a record of packages required for the project in a linked private package library. This ensures

* Package installations do not over-write your existing (global) package libraries.
* Package versions are the same as those used within this project.

The following call should install (or copy across from your existing global library) packages that are required for the project 
```{r message=FALSE, warning=FALSE}
renv::restore()
```

```{r message=FALSE, warning=FALSE}

library(gtsummary) # to enable creation of print-ready tables
library(gt) # to enable creation of print-ready tables
library(robvis) # for producing risk of bias summary figures
library(patchwork) # for composite figures
library(mgcv) # For exploring non-linear relationships between covariates and outcomes using GAM.
library(lme4) # for generalised linear mixed model (GLMM) regression analysis #
library(effects) # To obtain and plot coefficients and residuals from GLM(M)
library(msm) # enables calculation of DOR confidence intervals by delta-method #
library(ggeffects) # provides easy conversion of coefficients to predicted probabilities
library(partR2) # calculates semi-partial (part) R2 indicating % total variance explained by fixed effects of explanatory varaibles in a glmm.
library(DHARMa) # For residual diagnostics on generalised linear models
library(car) # For identifiying multi-colinearity by variable inflation factors (vif)
library(sjPlot) # For plotting predicted probabilities and model outputs
library(sjmisc)
library(sjlabelled)
library(lmtest)# allows comparison of nested models
library(meta4diag) # allows for Bayesian GLMM
library(binom) # allows calculation of exact binomial and Bayesian confidence intervals
library(LearnBayes) # For defining priors
library(ggpubr) # Assistance with graphics
library(multilevelTools)
library(GGally)
library(gridExtra) # Combining plots generated in base R
library(lattice) # For Q-Q plots
library(tidyverse) # to enable 'tidy' collection of packages, including dplyr, ggplot2, purrr, forcats, readr
```

## 1.3 Read in data and label
Read in the csv files "pnaat_desc_study" and "pnaat_desc" and prepare for descriptive statistics and meta-analysis.
```{r message=FALSE, warning=FALSE}
# Load study level data and define variables 
meta_study <- read_csv("pnaat_desc_study.csv", col_types = cols(
  wbgroup = col_factor()))
```
                       col_types =cols(
  wbgroup = col_factor(levels= c("High income","Upper-middle income", 
                                 "Lower-middle income","Low income"),
                                              ordered=TRUE),
  country = col_factor(),
  num_cohort = col_factor(),
  num_test = col_factor(),
  pubstat = col_factor(levels= c("Peer-reviewed and published",
                                 "Peer-reviewed pre-print",
                                 "Non-peer reviewed pre-print"),
                                              ordered=TRUE),
  quality = col_factor()))

meta_study <- meta_study %>% mutate (n_test = fct_relevel(
num_test,"1","2","3","5-8"))
meta_study <- meta_study %>% mutate (n_cohort = fct_relevel(
num_cohort, "1","2","3-5"))

# Load test evaluation level data and define variables
metadata <- read_csv ("pnaat_desc.csv", col_types = cols(
  wbgroup = col_factor(),
  country = col_factor(),
  pubstat = col_factor(levels= c("Peer-reviewed and published",
                                 "Peer-reviewed pre-print",
                                 "Non-peer reviewed pre-print"),
                                              ordered=TRUE),
  pool_size_gp = col_factor(levels=c("2","4 to 7", "8 to 15","16 to 31",
                                     "32+"),ordered=TRUE),
  symptoms = col_factor(levels=c("Asymptomatic","Mixed","Symptomatic")),
  naat = col_factor(levels=c("RT-PCR",
                         "Digital RT-PCR", "TMA", "Cartridge-based RT-PCR")),
  sample_pool = col_factor(),
  sample = col_factor(),
  pool_type = col_factor(),
  quality = col_factor(),
  modified_protocol = col_factor(),
  modint = col_factor(levels=c("lower","standard","higher")),
  pnaat = col_factor(),
  targets_for_pos = col_factor(levels=c("1 of 1", "1 of 2", "1 of 3",
                                        "2 of 2","2 of 3")),
  target = col_factor(levels=c("E","E, N, RdRp","E, Orf1ab","E, RdRp", 
                               "N", "N, Orf1ab","N, Orf1ab, S",
                               "N1, N2","N1, N3","Orf1ab")),
  storage = col_factor(),
  ref_std_same_sample = col_logical(),
  refstd_same_assay = col_logical(),
  refstd_same_time = col_logical(),
  refst_same_cutoff = col_logical(),
  regulatory_status = col_factor(),
  index_assay = col_factor(),
  refstd_assay = col_factor()))

# Create cohort level data
meta_cohort <- metadata %>% 
  group_by(cohort_id,symptoms,quality) %>% 
  summarise(maxparticipant = max(totalsamples), 
            maxdisease = max(disease_p),
            maxno_disease=max(disease_n), 
            maxweak_pos = max(weak_pos))
meta_cohort <- meta_cohort %>% mutate(positivity = maxdisease/maxparticipant*100)


# Add variable labels
meta_study <- meta_study %>% var_labels (
  study_id = "Number of studies",
  wbgroup = "Country income level classification (World Bank 2020)",
  pubstat = "Publication and peer-review status",
  n_cohort = "Number of cohorts per study",
  n_test = "Number of tests per study")

meta_cohort <- meta_cohort %>% var_labels (
  cohort_id = "Number of cohorts",
  maxparticipant = "Total participants tested (n)",
  maxdisease = "Total participants with disease (positives) (n)",
  maxno_disease = "Total participants without disease (negatives) (n)",
  maxweak_pos = "% Positives with low viral load per cohort",
  positivity = "% Test positivity per cohort",
  symptoms = "Symptom status of cohort")

metadata <- metadata %>% var_labels(
  study_id = "Number of studies",
  wbgroup = "Country income level classification (World Bank 2020)",
  pubstat = "Publication and peer-review status",
  cohort_id = "Cohorts",
  cohort = "Cohorts within study",
  t_p = "True positives",
  f_p = "False positives",
  t_n = "True negatives",
  f_n = "False negatives",
  eval_id = "Number of test evaluations",
  disease_p = "Infected with SARS-CoV-2",
  disease_n = "Not infected with SARS-CoV-2",
  totalsamples = "Total participants",
  pnaat = "pNAAT design",
  pool_size = "Pool size (n)",
  pool_size_gp = "Pool size",
  symptoms = "Symptom status",
  naat = "Test technology",
  sample_pool = "Sample type and pooling method",
  sample = "Sample type",
  pool_type = "Pooling method",
  weak_pos = "% Weak positives (low VL)",
  multipos = "% Pools containing >1 positive sample",
  quality = "Eligibility for meta-analysis",
  positivity_rate = "% Test positivity ",
  lod = "Limit of detection (copies per mL)",
  targets_for_pos = "Number of targets for positive in index pool test",
  target = "Gene targets for index test",
  num_target = "Number of targets assessed",
  modified_protocol = "Modified from IFU or protocol",
  modified_interpret = "Modified interpretation",
  ref_std_same_sample = "Reference standard based on same sample",
  refstd_same_assay = "Reference standard based on same NAAT assay",
  refstd_same_time = "Index test performed at same time as reference standard",
  refst_same_cutoff = "Reference standard uses same Cq cut-off",
  regulatory_status = "Index test regulatory status",
  storage = "Storage before index test",
  disease35_p = "Infected with SARS-CoV-2 by cut-off Cq 35",
  disease35_n = "Not infected with SARS-CoV-2 by cut-off Cq 35",
  t35_p = "True positives for cut-off of Cq 35",
  f35_p = "False positives for cut-off of Cq 35",
  t35_n = "True negatives for cut-off of Cq 35",
  f35_n = "False negatives for cut-off of Cq 35",
  index_assay = "Index test brand",
  refstd_assay = "Reference standard brand")
# Transform variables for further analysis  
metadata <- metadata %>% mutate(log2p = log(pool_size,2))
metadata <- metadata %>% mutate(log2lod = log(lod,2))
metadata <- metadata %>% mutate(tma = if_else(naat=="TMA",1,0))
metadata <- metadata %>% mutate(rtpcr = if_else(naat=="RT-PCR",1,0))
metadata <- metadata %>% mutate(cbpcr = if_else(naat=="Cartridge-based RT-PCR",1,0))
metadata <- metadata %>% mutate(ddpcr = if_else(naat=="Digital RT-PCR",1,0))
metadata <- metadata %>% mutate(multitube = if_else(
                                    sample_pool=="swab multitube",1,0))
metadata <- metadata %>% mutate(swabrna = if_else(
                                    sample_pool =="swab extracted RNA",1,0))
metadata <- metadata %>% mutate(salivadirect = if_else(
  sample_pool=="saliva direct",1,0))
metadata <- metadata %>% mutate(salivarna = if_else(
  sample_pool=="saliva extracted RNA",1,0))
metadata <- metadata %>% mutate(swabmedia = if_else(
  sample_pool=="swab media",1,0))
metadata <- metadata %>% mutate(rna = if_else(
  pool_type=="RNA",1,0))
```

# 2. Descriptive Statistics

## 2.1 Table 1 Description of studies
Generate Table 1.
```{r message=FALSE}
# Select variables for each sub-table
meta_top <- meta_study %>% dplyr::select(study_id, wbgroup,pubstat,n_cohort, n_test, quality)

meta_mid <- meta_cohort %>% dplyr::select(cohort_id, maxparticipant, maxdisease,
                                   maxno_disease, positivity,
                                   maxweak_pos, symptoms, quality)

meta_low <- metadata %>% dplyr::select(eval_id, pnaat, pool_size_gp, 
                                       multipos, naat,
                                sample, pool_type, index_assay,
                                regulatory_status, lod, targets_for_pos,
                                target, refstd_same_time, storage,
                                ref_std_same_sample, refstd_same_assay,
                                refst_same_cutoff, quality)

# Create sub-tables
t1<- tbl_summary(meta_top, by=quality, statistic = list(
  all_continuous() ~ "{median} ({p25} to {p75})", 
  study_id ~"{n_distinct}"))  %>% add_overall() %>%   
  modify_header(update = list(stat_0 ~ "**All**" , 
                              stat_1 ~ "**Single-gate**", 
                              stat_2 ~ "**Two-gate**"))
t2<- tbl_summary(meta_mid, by=quality, statistic = list(
  all_continuous() ~ "{median} ({p25} to {p75})", 
  cohort_id ~"{n_distinct}", 
  maxparticipant ~"{sum}", 
  maxdisease ~"{sum}", 
  maxno_disease ~"{sum}")) %>%  add_overall()

t3 <- tbl_summary(meta_low, by=quality, statistic = list(
  all_continuous() ~ "{median} ({p25} to {p75})", 
  eval_id ~"{n_distinct}"))  %>% add_overall()
# Stack the sub-tables into combined final table
stacked <- tbl_stack(list(t1,t2,t3)) %>% modify_spanning_header(
  c("stat_1", "stat_2") ~ "**Eligible for primary meta-analysis**") %>%
  modify_footnote(update = all_stat_cols() ~ "median (IQR) or n (%)")

stacked <- stacked %>% as_gt() %>% fmt_markdown(columns = TRUE) %>%
  gt::tab_source_note(gt::md("**LDT:** laboratory developed test; **pNAAT:** pooled nucleic acid amplification test; **RT-PCR:** reverse-transcription polymerase chain reaction; **TMA:** transcription mediated amplification;"))%>%
  tab_row_group(
    "Test evaluations", rows=30:114)  %>% tab_row_group(
    "Cohorts", rows=20:29)  %>% tab_row_group(
    "Studies", rows=1:19) %>% opt_table_font(
      font= google_font("Source Sans Pro")) %>% tab_options(
      row_group.background.color = "#CFD7E4", row_group.font.weight = "bold",
      table_body.hlines.color ="black",
      row_group.border.bottom.color = "black",
       row_group.border.bottom.width = px(1),
       row_group.border.top.width = px(1),
        heading.border.bottom.width = px(1),
        heading.border.bottom.color = "black",
        row_group.border.top.color = "black",
       footnotes.border.bottom.color = "black",
       footnotes.border.bottom.width = px(1),
       column_labels.border.top.color = "black",
       column_labels.border.top.width = px(1),
       table_body.border.top.color="black",
       table_body.border.bottom.color="black",
       table_body.border.top.width =px(1),
       table_body.border.bottom.width=px(1),
      source_notes.border.bottom.width = px(1),
      source_notes.border.bottom.color ="black",
       table.font.size = px(12)) 
stacked
```
# 3. Meta-analysis

## 3.1 Prepare data for meta-analysis
Reshape the 'metadata' tibble (created above) for bivariate binomial meta-analysis. The new tibble called 'Y' incorporates:

* One line each for data needed for sensitivity (diseased and true positives) and specificity (not diseased and true negatives) within each test evaluation,
* Dummy variables indicating rows referring to sensitivity or specificity
* Data for all other variables duplicated for sensitivity and specificity

```{r message=FALSE, warning=FALSE}
# convert metadata to dataframe for glmer compatibility
ma2 <- as.data.frame(metadata)

# transform covariates of proportions by folded square root (sQRT(x)-SQRT(1-x))
ma2 <- ma2 %>% mutate(weak_posfold = weak_pos^(1/2)-(1-weak_pos)^(1/2))
ma2 <- ma2 %>% mutate(positivity_ratefold = positivity_rate^(1/2)-(1-positivity_rate)^(1/2))
ma2 <- ma2 %>% mutate(multiposfold = multipos^(1/2)-(1-multipos)^(1/2))


# Create additional variables and reshape for bivariate analysis with dummy variables for sensitivity and specificity
ma2$n1 <- ma2$t_p + ma2$f_n # define number with disease
ma2$n0 <- ma2$t_n + ma2$f_p # define number without disease
ma2$true1 <- ma2$t_p # define true positives
ma2$true0 <- ma2$t_n # define true negatives
ma2$testeval <- 1:73 #give unique study id
ma2 <- ma2 %>% slice_head(n=73)

Y1 <- reshape(ma2, direction="long", 
               varying=list(c("n1","n0"), c("true1","true0")),
               timevar="sens",times=c(1,0),v.names=c("n","true"))

Y1 <- Y1 %>% var_labels(
  n = "Number by reference standard",
  true = "Number by index test")
Y1 = Y1[order(Y1$study),]
Y1$spec <- 1-Y1$sens
Y1se <- Y1 %>% filter(sens==1)
Y1se$naat <- dplyr::recode(Y1se$naat, "Cartridge-based RT-PCR" = "RT-PCR")
Y1se$naat <- forcats::fct_relevel(Y1se$naat,"RT-PCR")
Y1se$naat = relevel(Y1se$naat, ref="RT-PCR")

# Create separate datasets for "minipool" "matrix" and "combinatorial"
# Bivariate model datasets
ymp2 <- Y1 %>% filter(pnaat=="Minipool",pool_size_gp =="2") # minipool size 2
ymp4_7 <- Y1 %>% filter(pnaat=="Minipool",pool_size_gp =="4 to 7") # minipool size 4 to 7
ymp8_15 <- Y1 %>% filter(pnaat=="Minipool",pool_size_gp =="8 to 15") # minipool size 8 to 15
ymp16_31 <- Y1 %>% filter(pnaat=="Minipool",pool_size_gp =="16 to 31") #minipool size 16 to 31
Y1mp <- Y1 %>% filter(pnaat=="Minipool")  # for minipool (all sizes) #
Y1mp$naat <- dplyr::recode(Y1mp$naat, "Digital RT-PCR" = 2)
Y1mp$naat <- dplyr::recode(Y1mp$naat, "TMA" = 3)
y1mat <- Y1 %>% filter(pnaat=="Matrix")  # for matrix #
y1com <- Y1 %>% filter(pnaat=="Combinatorial")  # for combinatorial #
Y1mp <- Y1mp %>% mutate(outcome = true/n)
# Univariate model datasets
ysemp2 <- Y1se %>% filter(pnaat=="Minipool",pool_size_gp =="2") # minipool size 2
ysemp4_7 <- Y1se %>% filter(pnaat=="Minipool",pool_size_gp =="4 to 7") # minipool size 4 to 7
ysemp8_15 <- Y1se %>% filter(pnaat=="Minipool",pool_size_gp =="8 to 15") # minipool size 8 to 15
ysemp16_31 <- Y1se %>% filter(pnaat=="Minipool",pool_size_gp =="16 to 31") #minipool size 16 to 31
y1semp <- Y1se %>% filter(pnaat=="Minipool")  # for minipool (all sizes) #
y1semat <- Y1se %>% filter(pnaat=="Matrix")  # for matrix #
y1secom <- Y1se %>% filter(pnaat=="Combinatorial")  # for combinatorial

y1semp <- y1semp %>% var_labels(
  naat = "NAAT type",
  reg = "Regulatory approved test",
  weak_posfold = "Positives with low viral load (fsr)",
  multiposfold = "Pools with >1 positive sample (fsr)",
  positivity_ratefold="Test positivity rate (fsr)",
  log2p = "Log 2 pool size",
  log2lod = "Log 2 limit of detection (copies/mL)",
  modified_interpret = "Modified pool test cut-off",
  modified_protocol = "Modified test protocol")
y1semp <- y1semp %>% mutate (modified_protocol=as.factor(modified_protocol))
y1semp<- y1semp %>% mutate(reg = as.factor(reg))
y1semp<- y1semp %>% mutate(sensitivity = t_p/disease_p)


# Grand-mean centre all continuous variables
gmc2 <- function(x) {
    xcenter = mean(x)
    x - xcenter
}

y1semp <- y1semp %>% mutate(across(c(weak_posfold, positivity_ratefold, multiposfold, modified_interpret, log2lod, log2p, pool_size, weak_pos), ~gmc2(.x), "{.col}"))


```


## 3.2 Summary estimates by pNAAT design

### 3.2.1 Initial asssessment of heterogeneity
Use:

#### Visual inspection of paired forest plots
madad(x = NULL, TP, FN, FP, TN, level = 0.95, correction = 0.5, 
  correction.control = "all", method = "wilson", yates = TRUE, 
  suppress = TRUE, ...)
#### Galbraith plot

#### Influence diagnostics (removing (a) test evaluations (b) studies) using
influence.merMod from the package lme4.

#### Check if assumption of gaussian distribution to random effects holds using sjPlot

Observations:

* Visual inspection of paired forest plots for all evaluations suggests substantial heterogeneity in sensitivity but specificity approaching 100% across all evaluations
* No clear evidence of a threshold (cut-off) effect: Spearman correlation analysis between sensitivity and false positive rate is = -0.08 suggesting no clear evidence of a threshold (cut-off) effect.
* 

### 3.2.2 Combinatorial
Only a single study was identified (Chakraborty 2020 [A-C]) which employed a combinatorial pooled test approach to a representative set of specimens. Three slight variants of the approach were assessed on three cohorts. 
Since there was 0 FNs and only 1 FP across the three cohorts, bivariate binomial models would demonstrate singularity. It was therefore decided to sum TP,FP,TN, and FN across the cohorts and to estimate sensitivity and specificity using binomial exact method and Bayesian inference.

#### Estimate sens and spec (and 95% CIs) using the binomial exact method
```{r message=FALSE, warning=FALSE}
ycomsens <-c(binom.test(25,25)$estimate, binom.test(25,25)$conf.int)
ycomspec <-c(binom.test(1765,1766)$estimate, binom.test(1765,1766)$conf.int)
ycomsens
ycomspec
```


#### Estimate sens and spec (and 95% CIs) using Bayesian inference
To obtain 95% CI by Bayesian inference, we used both default and user-defined values for the shape parameters 'a' and 'b' describing the prior beta distribution.

The following code defines the prior beta distribution using expected 50th and 90th centiles of sensitivity and specificity distributions
```{r message=FALSE, warning=FALSE}
sens_ab <- beta.select(list(x = 0.90, p = 0.5), list(x = 0.98, p = 0.9))
spec_ab <- beta.select(list(x = 0.97, p = 0.5), list(x = 0.999, p = 0.9))
sens_ab
spec_ab
```


##### Sensitivity
```{r message=FALSE, warning=FALSE}
# Using user-defined values
ycombaysian_sens <- binom.bayes(25,25,prior.shape1 = sens_ab[1], prior.shape2 = sens_ab[2])
print(ycombaysian_sens)
binom.bayes.densityplot(ycombaysian_sens )
# Using  default values
ycombaysian_sens2 <- binom.bayes(25,25,prior.shape1 = 0.5, prior.shape2 =0.5)
print(ycombaysian_sens2)
binom.bayes.densityplot(ycombaysian_sens2)
```


##### Specificity
```{r message=FALSE, warning=FALSE}
ycombaysian_spec <- binom.bayes(1765,1766,prior.shape1 = spec_ab[1], prior.shape2 = spec_ab[2])
print(ycombaysian_spec)
binom.bayes.densityplot(ycombaysian_spec)
ycombaysian_spec2 <- binom.bayes(1765,1766,prior.shape1 = 0.5, prior.shape2 =0.5)
print(ycombaysian_spec2)
binom.bayes.densityplot(ycombaysian_spec2)
```


### 3.2.3 Matrix
Only a single study was identified (Ben-Ami 2020 [B]) which employed a matrix pooled test approach to a representative set of specimens.

#### Estimate sens and spec (and 95% CIs) using the binomial exact method
```{r message=FALSE, warning=FALSE}
ymatsens <-c(binom.test(3,3)$estimate, binom.test(3,3)$conf.int)
ymatspec <-c(binom.test(72,72)$estimate, binom.test(72,72)$conf.int)
ymatsens
ymatspec
```

#### Estimate sens and spec (and 95% CIs) using Bayesian method
Use default prior beta distribution (a = 0.5, b=0.5) and user-defined priors by specifying quantiles:
Sensitivity: 50th centile = 0.90, 90th centile =0.98
Specificity: 50th centile = 0.97, 90th centile = 0.999
Calculate the first and second beta distribution shapes based on these quantiles
```{r message=FALSE, warning=FALSE}
sens_ab <- beta.select(list(x = 0.90, p = 0.5), list(x = 0.98, p = 0.9))
spec_ab <- beta.select(list(x = 0.97, p = 0.5), list(x = 0.999, p = 0.9))
sens_ab
spec_ab
```
To obtain 95% CI by Bayesian inference, we use the same priors as defined in summarising sensitivity and specificity of combinatorial designs.

##### Sensitivity
```{r message=FALSE, warning=FALSE}
ymatbaysian_sens <- binom.bayes(3,3,prior.shape1 = sens_ab[1], prior.shape2 = sens_ab[2])
print(ymatbaysian_sens)
binom.bayes.densityplot(ymatbaysian_sens )
ymatbaysian_sens2 <- binom.bayes(3,3,prior.shape1 = 0.5, prior.shape2 =0.5)
print(ymatbaysian_sens2)
binom.bayes.densityplot(ymatbaysian_sens2)
```

##### Specificity
```{r message=FALSE, warning=FALSE}
ymatbaysian_spec <- binom.bayes(72,72,prior.shape1 = spec_ab[1], prior.shape2 = spec_ab[2])
print(ymatbaysian_spec)
binom.bayes.densityplot(ymatbaysian_spec)
ymatbaysian_spec2 <- binom.bayes(72,72,prior.shape1 = 0.5, prior.shape2 =0.5)
print(ymatbaysian_spec2)
binom.bayes.densityplot(ymatbaysian_spec2)
```

### 3.2.4 Minipool
The review identified 69 evaluations of minipool tests across 37 cohorts. Review of the paired forest plots indicates substantial between-study variance in sensitivity but specificity approached 1.00 in all studies (minimal between-study variance).
Based on these observations use the glmer function in "lme4" to fit:

* Model 1: A bivariate binomial random-effects model with an unstructured covariance matrix: random-effects considered for both sensitivity and specificity with unknown correlation (This was fit to confirm random-effects for specificity were not required)
* Model 2: A bivariate binomial random-effects model with zero covariance matrix: random-effects considered for both sensitivity and specificity but with no correlation between 
* Model 3: A bivariate binomial partial random-effects model: random-effects are considered for sensitivity but not for susceptibility.
* Model 4: univariate binomial random-effects model: looking only at sensitivity.

#### model 1 bivariate binomial random-effects with unstructured covariance matrix
Use glmer to fit an integer only bivariate binomial multi-level (random-effects) meta-analysis with an unstructured covariance matrix.
```{r message=FALSE, warning=FALSE}
ymp_mod1 <- glmer (formula= cbind(true,n-true)~0+sens+spec+(0+sens+spec|testeval),
                    data = Y1mp,family=binomial,nAGQ=1,verbose=0)
ymp_mod1_sum <- summary(ymp_mod1)
ymp_mod1_sum
ci <- confint(ymp_mod1)
plogis(ci)
```
Observations

* Confirms substantial between-studies variance among mini-pool designs
* Correlation of fixed effects is low (~0.15).
* Covariance in random effects = 1 suggesting over-fitting and need to reduce model complexity
* Overall suggests a similar model with either a zero correlation covariance matrix (model 2 below) or considering no random-effects in specificity (model 3 below) more appropriate.

#### model 2 bivariate binomial random-effects with zero covariance matrix
Use glmer to fit an integer only bivariate binomial multi-level (random-effects) meta-analysis with a zero covariance matrix.
```{r message=FALSE, warning=FALSE}
ymp_mod2 <- glmer (formula= cbind(true,n-true)~0+sens+spec+(0+sens|testeval)+(0+spec|testeval),
                    data = Y1mp,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod2_sum <- summary(ymp_mod2)
ymp_mod2_sum
co <- ymp_mod2_sum$coeff[1:2,1]
ci2 <- confint  (ymp_mod2)
plogis(co)
plogis(ci2)
```
Observations:

* The estimates for sensitivity (0.941) and specificity (~1.00) are similar to model 1.
* However, the between-studies variance is limited to sensitivity, with between-studies variance in specificity ~0 which is more consistent with observations.
*  Overall suggests a model considering no random-effects in specificity (model 3 below) or a univariate model focused on sensitivity (model 4 below) more appropriate.


#### Model 3: Bivariate binomial partial random effects model 
```{r message=FALSE, warning=FALSE}
ymp_mod3 <- glmer (formula= cbind(true,n-true)~0+sens+spec+(0+sens|testeval),
                    data = Y1mp,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod3_sum <- summary(ymp_mod3)
co <- ymp_mod3_sum$coeff[1:2,1]
ci3 <- confint  (ymp_mod3)
plogis(co)
plogis(ci3)
```
Observations:

* Estimated sensitivity (0.941) and specificity (~1.00) are similar to model 1.
* The between-studies variance for sensitivity is ~ the same in model 2.
* BIC is slightly better than model 1 and 2 suggesting a more parsimonious model
* Confirms a model with no random-effects in specificity appropriate. 
* Since specificity approaches unity in all studies and cohorts, a univariate model focused on sensitivity (model 4 below) may be more appropriate.

#### model 4 Sensitivity only model
Use glmer to fit an integer only univariate (outcome  is sensitivity only) binomial multi-level (random-effects) meta-analysis

##### Cohort at level 2
```{r message=FALSE, warning=FALSE}

# Cohort as level 2
ysemp1 <- glmer (formula= cbind(true,n-true)~ 1+(1|cohort_id),
                    data = y1semp,family=binomial, nAGQ=1,verbose=0) 
ysemp1_sum <- summary(ysemp1)
ysemp1_sum
co <- 
ci <- confint  (ysemp1)
plogis(co)
plogis(ci)
```

##### study as level 2
```{r message=FALSE, warning=FALSE}
ysemp2 <- glmer (formula= cbind(true,n-true)~ 1+(1|testeval),
                    data = y1semp,family=binomial, nAGQ=1,verbose=0) 
ysemp2_sum <- summary(ysemp2)
ysemp2_sum
```

##### Nested (studies are nested within cohorts)
```{r message=FALSE, warning=FALSE}
ysemp3 <- glmer (formula= cbind(true,n-true)~ 1+(1|testeval/cohort_id),
                    data = y1semp,family=binomial, nAGQ=1,verbose=0) 
ysemp3_sum <- summary(ysemp3)
ysemp3_sum
```
##### Compare models
```{r message=FALSE, warning=FALSE}
lrtest(ysemp3,ysemp2,ysemp1)
```
Observations

* 55% to 67% of total variation in sensitivity occurs between cohorts or test-evaluations (h)
* A generalised linear mixed model (glmm) with random-effects at the test-evaluation level captures between-study variation efficiently.
* A 3-level model with random effects for test evaluations nested within cohorts is also suitable but may result in over-fitting.

## 3.3 Sub-group analyses

### 3.3.1 Pool size groups
```{r message=FALSE, warning=FALSE}
ymp_mod2 <- glmer (formula= cbind(true,n-true)~0+sens+spec+
(0+sens|testeval), data = ymp2,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod2_sum <- summary(ymp_mod2)
ymp_mod2_sum

ymp_mod4_7 <- glmer (formula= cbind(true,n-true)~0+sens+spec+
(0+sens|testeval), data = ymp4_7,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod4_7_sum <- summary(ymp_mod4_7)
ymp_mod4_7_sum

ymp_mod8_15 <- glmer (formula= cbind(true,n-true)~0+sens+spec+
(0+sens|testeval), data = ymp8_15,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod8_15_sum <- summary(ymp_mod8_15)
ymp_mod8_15_sum

ymp_mod16_31 <- glmer (formula= cbind(true,n-true)~0+sens+spec+
(0+sens|testeval), data = ymp16_31,family=binomial,nAGQ=1,verbose=0) # fixed + random model
ymp_mod16_31_sum <- summary(ymp_mod16_31)
ymp_mod16_31_sum
```

### 3.3.1 Symptom status and pool size group

### 3.3.2 NAAT technology and pool size group

### 3.3.3 Sample and pool size group

### 3.3.4 Pooling method and pool size group


## 3.4 Meta-regression exploring heterogeneity
Meta-regressions were conducted for:

(a) Sensitivity as outcome (univariate) and test evaluation as level 2 variable
(b) Sensitivity as outcome (univariate) and cohort as level 2 variable
(c) Sensitivity and specificity as outcome (bivariate) and test evaluation as level 2 variable, with random effects for sensitivity only and separate fixed effects for sensitivity and specificity
(d) Sensitivity and specificity as outcome (bivariate) and cohort as level 2 variable,  with random effects for sensitivity only and separate fixed effects for sensitivity and specificity

* A block-wise backwards-elimination approach in which covariates were entered in groups (blocks) defined a priori on the basis of theoretical importance:
   * Block 1 (matchiing sub-groups): naat, symptoms, pool size, sample type,
   pooling method, proportion weak positives
   * Block 2: proportion pools containing >1 positive sample, quality group,
   limit of detection (lod), positivity rate
   * Block 3: modified protocol, modified interpretation, regulatory status,
   number of targets, number of targets amplified for positive result, target
   genes, storage of samples, reference standard same time, reference standard
   same sample, reference standard same assay.

* After entering the first block, we removed covariates, starting with those non-significantly associated with sensitivity and highly colinear with other variables. We reviewed BIC and likelihood-ratio after removing variables to determine if the covariate could be removed without compromising model fit. This continued until only covariates that were significant (at a=0.05) and improved model fit (according to lrtest) were retained.
* This process was applied for second and third rank blocks.

### 3.4.1 Exploring relationships between continuous covariates and sensitivity
Before meta-regression we examine nature of relationships between independent variables (continuous covariates) and outcomes (sensitivity, specificity):

* Since we use a logit link in the binomial model we examine relationships between the inverse logit of covariates and sensitivity (i.e TP as proportion of all with disease (TP+FN)).
* Continuous variables reflecting proportions (*weak_pos:* positives with low-viral load; *positivity_rate:* tested samples positive for SARS-CoV-2; *multipos:* positive pools containing >1 positive sample) were transformed by folded root [x^(1/2)-(1-x)^(1/2)] to ensure bounded by 0 and 1.
* We considered non-linear relationships between explanatory variables and outcomes

```{r message=FALSE, warning=FALSE}
y1semp<- y1semp %>% mutate(sensitivity = t_p/disease_p)
y1sempexp<- y1semp %>% mutate(logit = log(sensitivity/(1-sensitivity)))
y1semp_explore <- y1sempexp %>% dplyr::select(
  weak_posfold, multiposfold,positivity_ratefold, log2p, log2lod,logit,sensitivity,mod, modified_interpret)
predictors <- colnames(y1semp_explore)


y1semp_explore1 <-y1semp_explore %>%
  gather(key = "predictors", value = "predictor.value", 
         -c(logit,sensitivity, weak_posfold, multiposfold, positivity_ratefold,
            modified_interpret))

plot1 <- ggplot(y1semp_explore1, aes(predictor.value, logit))+
  geom_point(size = 0.3, alpha = 0.5) +
  geom_smooth(method = "loess", size = 0.5) + 
  geom_smooth(method = "lm", color="darkred", linetype="dashed", size = 0.5, se=FALSE) + 
  facet_wrap(~predictors, scales = "free_x")+
  labs(y = "Logit Sensitivity", x = "Log 2 of Limit of detection (lod), Pool size (p), Modified cut-off+5",
        title = "Associations between grand-mean centred continuous variables and sensitivity")


y1semp_explore2 <-y1semp_explore %>%
  gather(key = "predictors", value = "predictor.value", 
         -c(logit,sensitivity, log2p, log2lod,mod,modified_interpret))

plot2 <- ggplot(y1semp_explore2, aes(predictor.value, logit))+
  geom_point(size = 0.3, alpha = 0.5) +
  geom_smooth(method = "loess", size = 0.5) + 
  geom_smooth(method = "lm", color="darkred", linetype="dashed", size = 0.5, se=FALSE) + 
  facet_wrap(~predictors, scales = "free_x")+
  labs(y = "Logit Sensitivity", x = "Folded root of x")


ggarrange(plot1,plot2, ncol=1,nrow=2)
```
Observations:

*  Log2 of pool size (*log2p*) and the (folded root of) proportion of positives having low viral load (*weak_posfold*) were linearly and inversely associated with logit of sensitivity as anticipated.
* Less clear associations were seen with log 2 of the assay limit of detection (*log2lod*), proportion of positive pools containing more than 1 positive (*multiposfold*), and all were adequately described by linear relationships after appropriate transformations.

### 3.4.2 Exploring correlations between continuous covariates
```{r message=FALSE, warning=FALSE}
y1sempexp2 <- as_tibble(y1sempexp)
explanatory <-y1sempexp2 %>% dplyr::select(log2p,multiposfold,log2lod,weak_posfold, positivity_ratefold,mod)
write_csv(explanatory, "exp.csv")
cont <- read_csv("exp.csv")
GGally::ggpairs(cont, columns=1:6)
```

Observations:

*  Correlations were generally weak except for relations between pool size (log2p) and test positivity rate (-0.583) or multiple positives per pool (+0.479).
*  Simultaneous inclusion of these variables risks multi-colinearity

### 3.4.3 Homogeneity of variance between factor levels
```{r message=FALSE, warning=FALSE}

leveneTest(residuals(ysemp2) ~ y1semp$naat)
leveneTest(residuals(ysemp2) ~ y1semp$sample)
leveneTest(residuals(ysemp2) ~ y1semp$modified_protocol)
leveneTest(residuals(ysemp2) ~ y1semp$reg)
```

### 3.4.4 (a) Models with Random effects at test evaluation level

#### Block 1 model
```{r message=FALSE, warning=FALSE}
# Saturated Block 1 model 
ysemp4 <- glmer (formula= cbind(true,n-true)~ 1+weak_posfold+naat+symptoms+log2p+sample+pool_type+(1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp4_sum <- summary(ysemp4)

ysemp5 <- glmer (formula= cbind(true,n-true)~ 1+weak_posfold+naat+log2p+sample+(1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp5_sum <- summary(ysemp5)
ysemp5_sum
```
#### Block 2 model
```{r message=FALSE, warning=FALSE}
# Saturated Block 2 model 
ysemp6 <- glmer (formula= cbind(true,n-true)~ 1+weak_posfold+naat+log2p+sample+multiposfold+quality+log2lod+positivity_ratefold+ (1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp6_sum <- summary(ysemp6)
ysemp6_sum

ysemp7 <- glmer (formula= cbind(true,n-true)~ 1+weak_posfold+log2p+naat+sample+
                   (1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp7_sum <- summary(ysemp7)
ysemp7_sum
```

#### Block 3 model
modified protocol, modified interpretation, regulatory status,
   number of targets, number of targets amplified for positive result, target
   genes, storage of samples, reference standard same cut-off and assay.
```{r message=FALSE, warning=FALSE}
# Saturated Block 3 model 
ysemp8 <- glmer (formula= cbind(true,n-true)~1+weak_posfold+naat+log2p
                 +sample+modified_protocol+modint+reg+storage+refst_same_cutoff+refstd_same_assay+
                   (1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp8_sum <- summary(ysemp8)

# FINAL BEST FIT MODEL
ysemp9 <- glmer (formula= cbind(true,n-true)~1+naat+log2p
                 +sample+modified_protocol+weak_posfold+modified_interpret+reg+
                   (1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp9_sum <- summary(ysemp9)
ysemp9_sum

```

#### Diagnostics on final block 3 model
```{r message=FALSE, warning=FALSE}
# Obtain residuals
simulationOutput <- simulateResiduals(ysemp9, plot = T)

# Check for under/over dispersion
testDispersion(simulationOutput)

# Check of residuals against predictors
testCategorical(simulationOutput, catPred = y1semp$reg)
testCategorical(simulationOutput, catPred = y1semp$naat)
testCategorical(simulationOutput, catPred = y1semp$modified_protocol)

# Check for homogeneity of variance over range of continuous variables
testQuantiles(simulationOutput, predictor=y1semp$weak_posfold, plot=T)
testQuantiles(simulationOutput, predictor=y1semp$log2p, plot=T)
testQuantiles(simulationOutput, predictor=y1semp$modified_interpret, plot=T)

# Check for homogeneity of variance between categories of factors
leveneTest(residuals(ysemp9) ~ y1semp$naat)
leveneTest(residuals(ysemp9) ~ y1semp$sample)
leveneTest(residuals(ysemp9) ~ y1semp$modified_protocol)
leveneTest(residuals(ysemp9) ~ y1semp$reg)

# Check for multi-colinearity by VIF
car::vif(ysemp9) 
```

#### A model with basis splines for *weak_posfold* and *modified_interpret*
```{r message=FALSE, warning=FALSE}
ysemp10 <- glmer (formula= cbind(true,n-true)~1+naat+log2p+
                 sample+modified_protocol+bs(weak_posfold)+
                 bs(modified_interpret)+ reg+ (1|testeval),
                 data = y1semp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ysemp10_sum <- summary(ysemp10)
ysemp10_sum
lrtest(ysemp9,ysemp10)

# Obtain residuals
sim2 <- simulateResiduals(ysemp10, plot = T)

# Check for under/over dispersion
testDispersion(sim2)

# Check of residuals against predictors
testCategorical(sim2, catPred = y1semp$reg)
testCategorical(sim2, catPred = y1semp$naat)
testCategorical(sim2, catPred = y1semp$modified_protocol)

# Check for homogeneity of variance over range of continuous variables
testQuantiles(sim2, predictor=y1semp$weak_posfold, plot=T)
testQuantiles(sim2, predictor=y1semp$log2p, plot=T)
testQuantiles(sim2, predictor=y1semp$modified_interpret, plot=T)

# Check for homogeneity of variance between categories of factors
leveneTest(residuals(ysemp10) ~ y1semp$naat)
leveneTest(residuals(ysemp10) ~ y1semp$sample)
leveneTest(residuals(ysemp10) ~ y1semp$modified_protocol)
leveneTest(residuals(ysemp10) ~ y1semp$reg)

# Check for multi-colinearity by VIF
car::vif(ysemp10) 

plot_model(ysemp10, type = "eff", terms ="modified_interpret [all]")+ ylim (0,1)
plot_model(ysemp10, type = "eff", terms ="weak_posfold [all]")+ ylim (0,1)

```

Observations:

* Diagnostics on the final metaregression model suggest adequate overall fit, but potential misspecification of the functional relationship between *weak_posfold* (folded root of proportion positives with low viral load) and sensitivity.
* Fitting a model (*ysemp10*) with basis splines for *weak_posfold* and *modified_interpret* improved overall model fit (log-likelihood) but at expense of higher model complexity (BIC unchanged).
* The basis splines may be overfitting given limited data across some parts of the range of *weak_posfold* and *modified_interpret*
* To aid interpretability we have settled on *ysemp9* as the final metaregression.

#### Summarising metaregression (a)
```{r message=FALSE, warning=FALSE}
#### Summarising metaregression (a) results
ysemp9_table <- tab_model (ysemp2, ysemp7,ysemp9, 
                           show.p=FALSE, collapse.ci = TRUE,  show.reflvl = TRUE,
  pred.labels=c("Intercept","Weak positives (fsqroot)", "NAAT: digital PCR","NAAT: TMA", "log 2 of pool size","Sample type: saliva","Modified test protocol", "Modified pool test cut-off", "Regulatory approval: yes"),
  dv.labels=c("(A) Intercept only","(B) Block 1 and 2","(C) Block 3"))
ysemp9_table
```

```{r message=FALSE, warning=FALSE}
R2_9m <- partR2(ysemp9, data = y1semp, R2_type = "marginal", nboot = 10)
R2_9m
R2_9parts <- partR2(ysemp9, data = y1semp, partvars = c("reg", "naat","modified_interpret","modified_protocol","sample","log2p","weak_posfold"), R2_type= "marginal", nboot=10)
summary(R2_9parts)
```

#### Plots summarising sources of heterogeneity
```{r message=FALSE, warning=FALSE}
# "EFFECTS" PACKAGE EXAMPLES

# Plot modified_intepret
plot1 <- plot(predictorEffects(ysemp10,~ modified_interpret, residuals=TRUE),
     main="Modifed pool test cut-off", 
     axes = list(grid=TRUE,x=list(rug=TRUE, pool_size=list(lab ="Change in Cq cut-off(pool-standard)")), y=list(lab="Sensitivity", type="response",lim=c(0,1), ticks=list(at=c(0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0)))),
      partial.residuals=list(smooth=FALSE))

# Plot weak_posfold
plot2 <-plot(predictorEffects(ysemp10,~ weak_posfold, residuals = TRUE),
     main="Proportion of positives with low VL", 
     axes = list(grid=TRUE,x=list(rug=TRUE, pool_size=list(lab ="Proportion low VL")), y=list(lab="Sensitivity", type="response",lim=c(0,1), ticks=list(at=c(0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0)))),
     partial.residuals=list(smooth=FALSE))

# Plot log2p (pool size)
plot3 <- plot(predictorEffects(ysemp10,~log2p,residuals = TRUE), 
     main="Pool size", 
     axes = list(grid=TRUE,x=list(rug=TRUE, log2p=list(lab ="Pool size",
      ticks=list(at=c(2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32)))), y=list(lab="Sensitivity", type="response",lim=c(0,1), ticks=list(at=c(0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0)))),
     partial.residuals=list(smooth=FALSE))

```



```{r message=FALSE, warning=FALSE}
# "sjPlot" PACKAGE EXAMPLES

set_theme(base = theme_grey())
# Plot of Odds Ratios and Beta-coefficients (standardised coefficients)
por <- plot_model(ysemp9,sort.est=T, title = "Effects as Odds Ratios")
pbeta <- plot_model(ysemp9,sort.est=T, type = "std", title = "Beta-coefficients")
p <- ggplot(R2IR2, aes(x=reorder(term, estimate),y=estimate))
p + geom_pointrange(aes(ymin = CI_lower, ymax = CI_upper)) + coord_flip()+ 
    ggtitle("Inclusive R2") +
  xlab("Covariate") + ylab("R2")
por
pbeta


pool1 = function(x){
  2^(x+2.85895883542674)
}
pool2 = function(x){
   x<-ifelse(x<0, 0, x)
   log(x,2) - 2.85895883542674
 }

isq<-function(x){
  print(paste("isq",x))  #debug statement
  x<-ifelse(x<0, 0, x)
  sqrt(x)
}

plot_model(ysemp9, type="eff",terms=c("log2p","sample","naat"))+
  ggtitle("Marginal effects by pool size, sample type and NAAT type") +
  theme(legend.position="top")+
  scale_y_continuous(name = "Sensitivity", breaks=seq(0,1.0,0.1), labels = scales::percent)+
  scale_x_continuous(trans=scales::trans_new("sq", pool1, pool2))
#### Look into trans_new from scales package
```



```{r message=FALSE, warning=FALSE}
# "ggeffects" PACKAGE EXAMPLES
theme_set(theme_ggeffects())
sampletype <- ggeffect(ysemp9, terms = c("log2p", "sample", "naat","weak_posfold [meansd]"))
sampletype <- sampletype %>% mutate(x = x+2.85895883542674)

sampletype2 <- ggemmeans(ysemp9, terms = c("log2p", "sample", "naat"), type="re",
                         condition=c(weak_posfold=-0.43408208))
sampletype2 <- sampletype2 %>% mutate(x = x+2.85895883542674)

ggplot(sampletype2, aes(x = x, y = predicted, group = group, colour = group, 
                       fill=group)) + 
  geom_line()+
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill=group), linetype=0, alpha = .2) +
facet_wrap(~facet) +
  scale_x_continuous("Pool size", breaks=c(0,1,2,3,4,5), labels=function(x){2^x})+
  scale_y_continuous("Sensitivity", breaks=seq(0,1,0.1))+
  theme(legend.position="top")+
  theme(panel.grid.minor = element_blank())+
  labs(title="Marginal effects by NAAT type, sample type, and pool size",
  fill= "Sample type", colour = "Sample type")

plot(sampletype2, facet = TRUE)+
  labs(title="Marginal effects by NAAT type, sample type, and pool size",
  colour="Sample type", fill="Sample type")+
  scale_x_continuous("Pool size", breaks=c(0,1,2,3,4,5), labels=function(x){2^x})+
  scale_y_continuous("Sensitivity", breaks=seq(0,1,0.1))+
  theme(legend.position="top")+
  theme(panel.grid.minor = element_blank())
```    
     
### 3.4.5 (b) Metaregression with test evaluation random effects for sensitivity and fixed specificity
```{r message=FALSE, warning=FALSE}
Y1mp <- Y1mp %>% mutate(selog2p = log2p*sens)
Y1mp <- Y1mp %>% mutate(splog2p = log2p*spec)
Y1mp <- Y1mp %>% mutate(sereg = reg*sens)
Y1mp <- Y1mp %>% mutate(spreg = reg*spec)
Y1mp <- Y1mp %>% mutate(semodified_interpret = modified_interpret*sens)
Y1mp <- Y1mp %>% mutate(semod_protocol = modified_protocol*sens)
Y1mp <- Y1mp %>% mutate(seweak_pos = weak_pos*sens)
Y1mp <- Y1mp %>% mutate(spweak_pos = weak_pos*spec)
Y1mp <- Y1mp %>% mutate(senaat2 = naat2*sens)
Y1mp <- Y1mp %>% mutate(spnaat2 = naat2*spec)
Y1mp <- Y1mp %>% mutate(semultipos = multipos*sens)
Y1mp <- Y1mp %>% mutate(facnaat = as.factor(senaat2))
Y1mp <- Y1mp %>% mutate(samp = if_else(sample=="Upper respiratory tract swab",1,0))
Y1mp <- Y1mp %>% mutate(sesamp=samp*sens)
Y1mp <- Y1mp %>% mutate(facsamp = as.factor(sesamp))
Y1mp$facnaat <- fct_relevel(Y1mp$facnaat,"3","2","1","0")
Y1mp <- Y1mp %>% mutate(modprot = if_else(modified_protocol=="T",1,0))
Y1mp <- Y1mp %>% mutate(modprot=modprot*sens)
Y1mp <- Y1mp %>% mutate(semodprot = as.factor(modprot))
```

```{r message=FALSE, warning=FALSE}
ypartmp17 <- glmer (formula= cbind(true,n-true)~0+spec+sens+selog2p+seweak_pos+facnaat+facsamp+semodified_interpret+semodprot+sereg+(0+sens|testeval),
                 data = Y1mp,family=binomial, nAGQ=1,verbose=0,
                 control=glmerControl(optimizer="bobyqa",optCtrl=list
                                      (maxfun=2e5)))
ypartmp17_sum <- summary(ypartmp17)
ypartmp17_sum
ypartmp17_residuals <-simulateResiduals(ypartmp17, plot = T)
testDispersion(ypartmp17_residuals)
```
```{r message=FALSE, warning=FALSE}
ysemp9a <- glmer(sensitivity~1+log2p*weak_posfold+(1|testeval),
                 weights=n, data=y1semp,family="binomial")
ysemp9a_sum <- summary(ysemp9a)
ysemp9a_sum
ggpredict(ysemp9a)
```